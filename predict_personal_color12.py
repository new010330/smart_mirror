import os
import cv2
import numpy as np
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image

# âœ… ê²½ë¡œ ì„¤ì •
MODEL_PATH = os.path.join('saved_models', 'final_model_efficientnet.pt')
CLASS_PATH = os.path.join('saved_models', 'class_names.txt')

# âœ… ëª¨ë¸ ë° í´ë˜ìŠ¤ ë¡œë“œ
def load_model_and_classes():
    if not os.path.exists(MODEL_PATH):
        print(f"âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")
        exit()
    if not os.path.exists(CLASS_PATH):
        print(f"âŒ í´ë˜ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {CLASS_PATH}")
        exit()

    model = models.efficientnet_b0(pretrained=False)
    with open(CLASS_PATH, "r", encoding="utf-8") as f:
        class_names = [line.strip() for line in f]
    model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(class_names))
    model.load_state_dict(torch.load(MODEL_PATH, map_location='cpu'))
    model.eval()
    model.to('cpu')  # âœ… ëª…ì‹œì ìœ¼ë¡œ CPUì— í• ë‹¹

    print(f"âœ… í´ë˜ìŠ¤ ëª©ë¡ ë¡œë“œ ì™„ë£Œ: {class_names}")
    return model, class_names

# âœ… ì–¼êµ´ crop í•¨ìˆ˜ (MediaPipe ì‚¬ìš©)
def crop_face(img):
    import mediapipe as mp
    mp_face_detection = mp.solutions.face_detection
    with mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5) as detector:
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        results = detector.process(img_rgb)
        if not results.detections:
            print("âš ï¸ ì–¼êµ´ ë¯¸ê²€ì¶œ - ì˜ˆì¸¡ ì¤‘ë‹¨")
            return None

        h, w, _ = img.shape
        box = results.detections[0].location_data.relative_bounding_box
        x = int(box.xmin * w)
        y = int(box.ymin * h)
        bw = int(box.width * w)
        bh = int(box.height * h)
        margin = int(0.2 * bh)

        x1 = max(0, x - margin)
        y1 = max(0, y - margin)
        x2 = min(w, x + bw + margin)
        y2 = min(h, y + bh + margin)
        return img[y1:y2, x1:x2]

# âœ… ì „ì²˜ë¦¬ ë³´ì • í•¨ìˆ˜ë“¤
def apply_hist_eq(img):
    ycrcb = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)
    ycrcb[:, :, 0] = cv2.equalizeHist(ycrcb[:, :, 0])
    return cv2.cvtColor(ycrcb, cv2.COLOR_YCrCb2RGB)

def simple_white_balance(img):
    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB).astype(np.float32)
    avg_a = np.mean(lab[:, :, 1])
    avg_b = np.mean(lab[:, :, 2])
    lab[:, :, 1] -= ((avg_a - 128) * (lab[:, :, 0] / 255.0) * 1.1)
    lab[:, :, 2] -= ((avg_b - 128) * (lab[:, :, 0] / 255.0) * 1.1)
    lab = np.clip(lab, 0, 255).astype(np.uint8)
    return cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)

def apply_clahe(img):
    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    lab[:, :, 0] = clahe.apply(lab[:, :, 0])
    return cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)

# âœ… ì˜ˆì¸¡ í•¨ìˆ˜
def predict_personal_color(image_path, model, class_names, debug=False):
    if not os.path.exists(image_path):
        return "ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.", None

    img = cv2.imread(image_path)
    if img is None:
        return "ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", None

    face_img = crop_face(img)
    if face_img is None:
        return "ì–¼êµ´ ì¸ì‹ ì‹¤íŒ¨", None

    img = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)
    img = simple_white_balance(img)
    img = apply_clahe(img)
    img = apply_hist_eq(img)

    if debug:
        print(f"ğŸ“ ì „ì²˜ë¦¬ í›„ ì´ë¯¸ì§€ í¬ê¸°: {img.shape}")

    img = cv2.resize(img, (224, 224))
    img = img.astype(np.float32) / 255.0
    img = (img - 0.5) / 0.5  # Normalize to [-1, 1]
    img = np.transpose(img, (2, 0, 1))  # HWC â†’ CHW
    img_tensor = torch.tensor(img).unsqueeze(0).to('cpu')  # âœ… CPU ëª…ì‹œ

    with torch.no_grad():
        outputs = model(img_tensor)
        probs = torch.softmax(outputs, dim=1)
        conf, pred_idx = torch.max(probs, dim=1)
        confidence = conf.item() * 100
        predicted_class = class_names[pred_idx.item()]

    if confidence < 30:
        print(f"âš ï¸ ì‹ ë¢°ë„ ë‚®ìŒ: {confidence:.2f}%")

    if debug:
        print("\nğŸ“Š í´ë˜ìŠ¤ë³„ í™•ë¥ :")
        for i, class_name in enumerate(class_names):
            print(f" - {class_name}: {probs[0][i]*100:.2f}%")

    return predicted_class, confidence

# âœ… ì‹¤í–‰ë¶€ í…ŒìŠ¤íŠ¸
if __name__ == '__main__':
    test_image = 'test33.jpg'
    print(f"ğŸ“· ì˜ˆì¸¡ ì‹œì‘: {test_image}")
    model, class_names = load_model_and_classes()
    result, confidence = predict_personal_color(test_image, model, class_names, debug=True)

    if confidence is not None:
        print(f"âœ… ì˜ˆì¸¡ ê²°ê³¼: {result} (ì‹ ë¢°ë„: {confidence:.2f}%)")
    else:
        print(f"âŒ ì˜ˆì¸¡ ì‹¤íŒ¨: {result}")
