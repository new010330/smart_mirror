import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models, transforms, datasets
from torch.utils.data import DataLoader, WeightedRandomSampler
from sklearn.utils.class_weight import compute_class_weight
import numpy as np

# âœ… ê²½ë¡œ ì„¤ì •
DATA_DIR = 'data'
SAVE_DIR = 'saved_models'
STAGE1_DIR = os.path.join(SAVE_DIR, 'stage1')
STAGE2_DIR = os.path.join(SAVE_DIR, 'stage2')
os.makedirs(STAGE1_DIR, exist_ok=True)
os.makedirs(STAGE2_DIR, exist_ok=True)

# âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„°
BATCH_SIZE = 32
EPOCHS = 100
LR_STAGE1 = 1e-4
LR_STAGE2 = 1e-5
IMG_SIZE = 224

# âœ… GPU ì„¤ì •
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("âœ… Using device:", DEVICE)

# âœ… ë°ì´í„° ì „ì²˜ë¦¬
train_transform = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

val_transform = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

# âœ… ë°ì´í„° ë¡œë”©
full_dataset = datasets.ImageFolder(DATA_DIR)
class_names = full_dataset.classes
num_classes = len(class_names)
with open(os.path.join(SAVE_DIR, "class_names.txt"), "w", encoding="utf-8") as f:
    f.writelines(name + "\n" for name in class_names)
print("âœ… í´ë˜ìŠ¤ ëª©ë¡ ì €ì¥ ì™„ë£Œ:", class_names)

# âœ… í›ˆë ¨/ê²€ì¦ ë¶„ë¦¬
train_size = int(0.8 * len(full_dataset))
val_size = len(full_dataset) - train_size
train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))
train_dataset.dataset.transform = train_transform
val_dataset.dataset.transform = val_transform

# âœ… oversamplingì„ ìœ„í•œ sampler ìƒì„±
autumn_classes = ['autumn_deep', 'autumn_soft', 'autumn_warm']
autumn_indices = [i for i, name in enumerate(class_names) if name in autumn_classes]
train_labels = [full_dataset[i][1] for i in train_dataset.indices]
sample_weights = [2.0 if label in autumn_indices else 1.0 for label in train_labels]
sample_weights = torch.DoubleTensor(sample_weights)
sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)

# âœ… í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
labels = [label for _, label in train_dataset]
class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(labels), y=labels)
class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(DEVICE)

# âœ… ëª¨ë¸ ìƒì„±
model = models.efficientnet_b0(pretrained=True)
model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)
model = model.to(DEVICE)

# âœ… ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €
criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)
optimizer = optim.Adam(model.parameters(), lr=LR_STAGE1)

# âœ… í•™ìŠµ í•¨ìˆ˜ ì •ì˜
def train(model, loader, optimizer, criterion):
    model.train()
    total_loss = 0
    for images, labels in loader:
        images, labels = images.to(DEVICE), labels.to(DEVICE)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    return total_loss / len(loader)

def validate(model, loader, criterion):
    model.eval()
    total_loss = 0
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            outputs = model(images)
            loss = criterion(outputs, labels)
            total_loss += loss.item()
            preds = outputs.argmax(dim=1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)
    return total_loss / len(loader), correct / total

# âœ… 1ë‹¨ê³„ í•™ìŠµ
print("\nğŸš€ 1ë‹¨ê³„ í•™ìŠµ ì‹œì‘")
best_val_acc = 0
for epoch in range(EPOCHS):
    train_loss = train(model, train_loader, optimizer, criterion)
    val_loss, val_acc = validate(model, val_loader, criterion)
    print(f"[{epoch+1:03d}] Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}")
    if val_acc > best_val_acc:
        best_val_acc = val_acc
        torch.save(model.state_dict(), os.path.join(STAGE1_DIR, 'best_model.pt'))

# âœ… 2ë‹¨ê³„ fine-tuning
print("\nğŸš€ 2ë‹¨ê³„ í•™ìŠµ ì‹œì‘ (fine-tuning)")
optimizer = optim.Adam(model.parameters(), lr=LR_STAGE2)
for param in model.features.parameters():
    param.requires_grad = True

best_val_acc = 0
for epoch in range(EPOCHS):
    train_loss = train(model, train_loader, optimizer, criterion)
    val_loss, val_acc = validate(model, val_loader, criterion)
    print(f"[{epoch+1:03d}] Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}")
    if val_acc > best_val_acc:
        best_val_acc = val_acc
        torch.save(model.state_dict(), os.path.join(STAGE2_DIR, 'best_model.pt'))

# âœ… ìµœì¢… ëª¨ë¸ ì €ì¥
final_path = os.path.join(SAVE_DIR, 'final_model_efficientnet.pt')
torch.save(model.state_dict(), final_path)
print(f"\nğŸ‰ ì „ì²´ í•™ìŠµ ì™„ë£Œ ë° ëª¨ë¸ ì €ì¥: {final_path}")
